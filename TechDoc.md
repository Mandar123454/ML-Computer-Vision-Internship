\# ğŸ§  Technical Documentation: Machine Learning Computer Vision Internship Projects



> \*\*Internship Period\*\*: 24 September â€“ 24 November 2025  

> \*\*Author\*\*: \Mandar Kajbaje 

> \*\*Contact\*\*: \mandarkajbaje@gmail.com 

---



\## ğŸ—‚ï¸ Folder Structure



The submission archive is organized for clarity and easy execution:

ğŸ“ ML\_ComputerVision\_Internship\_Submission\_Mandar\_Kajbaje/

â”‚

â”œâ”€â”€ ğŸ“„ Internship\_Report.pdf â† Complete report in PDF format

â”œâ”€â”€ ğŸ“„ TechDoc.md â† You are here!

â”œâ”€â”€ ğŸ“„ requirements.txt â† Python dependencies

â”œâ”€â”€ ğŸ“„ README\_FIRST.txt â† Quick-start guide

â”‚

â”œâ”€â”€ ğŸ“ notebooks/ â† All 6 Jupyter Notebooks (.ipynb)

â”‚ â”œâ”€â”€ 1\_Attendance\_System.ipynb

â”‚ â”œâ”€â”€ 2\_Animal\_Detection.ipynb

â”‚ â”œâ”€â”€ 3\_Drowsiness\_Detection.ipynb

â”‚ â”œâ”€â”€ 4\_Nationality\_Detection.ipynb

â”‚ â”œâ”€â”€ 5\_SignLanguage\_Detection.ipynb

â”‚ â””â”€â”€ 6\_CarColor\_Detection.ipynb

â”‚

â”œâ”€â”€ ğŸ“ models/ â† Saved model weights (if applicable)

â”‚ â””â”€â”€ \*.h5 / \*.pt / \*.pb

â”‚

â””â”€â”€ ğŸ“ assets/ â† Sample test media

â”œâ”€â”€ images/

â””â”€â”€ videos/

---



\## â–¶ï¸ How to Run the Projects



\### Step 1: Setup Environment

Ensure you have \*\*Python 3.8 or higher\*\* installed.



Create and activate a virtual environment (recommended):



```bash

python -m venv cv\_env

\# On Windows:

cv\_env\\Scripts\\activate

\# On macOS/Linux:

source cv\_env/bin/activate]



**Step 2: Install Dependencies**

From the root folder, run:

pip install -r requirements.txt



**Step 3: Launch Jupyter Notebook**

**jupyter notebook**



**âš™ï¸ Dependencies (requirements.txt)**

**All required libraries are listed below. Save this as requirements.txt:**

**tensorflow>=2.10.0**

**opencv-python>=4.5.0**

**mediapipe>=0.10.0**

**scikit-learn>=1.2.0**

**pandas>=1.5.0**

**numpy>=1.21.0**

**matplotlib>=3.7.0**

**Pillow>=9.0.0**

**imutils>=0.5.4**

**tk**

**jupyter**



**ğŸ¯ Project-Specific Notes**

**1. Attendance System Model**

**Uses FaceNet + SVM for recognition, FER CNN for emotion.**

**Only activates between 9:30 AM â€“ 10:00 AM (system time).**

**Output: attendance\_log.csv generated in project folder with timestamps.**

**No GUI â€” CLI/console based.**

**2. Animal Detection Model**

**Uses YOLOv5/SSD trained on custom/COCO animal dataset.**

**Carnivores highlighted in RED bounding boxes.**

**Pop-up message shows count of carnivorous animals detected.**

**GUI supports image upload + video feed + real-time preview.**

**3. Drowsiness Detection Model**

**Uses MediaPipe/Dlib facial landmarks â†’ eye/mouth aspect ratio â†’ binary classifier.**

**Sleeping persons marked in RED.**

**Predicts age using regression/classifier head.**

**Pop-up shows: â€œSleeping: 2 people â†’ Ages: 24, 31â€**

**GUI supports image + video input with preview.**

**4. Nationality Detection Model**

**Fine-tuned ResNet/ViT for nationality classification.**

**Emotion: FER model.**

**Dress color: HSV masking + dominant color extraction.**

**Conditional output logic:**

**Indian â†’ Age + Dress Color + Emotion**

**US â†’ Age + Emotion**

**African â†’ Dress Color + Emotion**

**Others â†’ Nationality + Emotion**

**GUI includes upload button, image preview, dynamic output panel.**

**5. Sign Language Detection**

**Trained on ASL/static gesture dataset using CNN or MediaPipe Hands + LSTM.**

**Only active between 6:00 PM â€“ 10:00 PM (system time check).**

**GUI supports:**

**Image upload â†’ single prediction**

**Live webcam â†’ real-time classification**

**Vocabulary: \[Specify your chosen words, e.g., â€œHelloâ€, â€œThank Youâ€, â€œYesâ€, â€œNoâ€]**

**6. Car Colour Detection Model**

**Vehicle detection: YOLOv5 or Haar Cascade.**

**Color detection: K-means clustering on ROI or dominant color via histogram.**

**Blue cars â†’ Red rectangle**

**Other cars â†’ Blue rectangle**

**Pedestrian count near traffic signal using pose/human detector.**

**GUI displays annotated image + counters.**

**âš ï¸ Troubleshooting \& Tips**

**Issue	Solution**

**GUI doesnâ€™t open / crashes	Ensure youâ€™re not running headless (SSH/server). Use local machine with display.**

**ModuleNotFoundError	Double-check requirements.txt and reinstall missing packages.**

**Time-based features not triggering	Ensure system clock matches expected timezone. Code uses datetime.now().time().**

**Low FPS in video processing	Reduce frame resolution, skip frames, or use lighter models (MobileNet, MediaPipe).**

**Model not detecting anything	Check confidence threshold â€” may be set too high. Lower it (e.g., from 0.7 â†’ 0.4).**

**Memory overload	Clear GPU cache after each prediction: tf.keras.backend.clear\_session()**

**ğŸ“Œ Additional Notes**

**All notebooks include markdown headers, inline comments, and sample outputs for clarity.**

**Screenshots of GUIs, pop-ups, and detection results are embedded within notebooks.**

**CSV logs (Attendance System) and confusion matrices (where applicable) are saved locally.**

**For reproducibility, random seeds are fixed where possible.**



